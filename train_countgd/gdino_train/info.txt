[32mINFO    [0m [32m2025-03-21 14:18:28,868 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:18:28,869 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:18:28,881 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:18:28,881 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:18:28,882 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:18:28,882 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:18:28,882 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, quiet=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:18:28,885 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:19:00,912 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:19:00,913 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:19:00,914 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:19:00,915 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:19:00,915 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:19:00,915 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:19:00,916 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, quiet=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:19:00,919 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:19:19,810 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:19:19,823 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:19:19,828 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:19:19,830 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:19:19,830 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:19:19,831 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:19:19,832 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, quiet=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:19:19,839 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:19:45,472 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:19:45,483 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:19:45,485 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:19:45,486 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:19:45,486 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:19:45,486 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:19:45,487 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, quiet=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:19:45,491 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:20:00,032 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:20:00,033 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:20:00,034 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:20:00,035 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:20:00,035 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:20:00,035 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:20:00,036 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, quiet=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:20:00,039 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:20:41,574 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:20:41,586 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/groundingdino_swinb_cogcoor.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:20:41,588 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:20:41,589 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:20:41,589 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:20:41,589 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:20:41,590 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/groundingdino_swinb_cogcoor.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, quiet=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:20:41,594 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:21:43,100 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:21:43,101 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/groundingdino_swinb_cogcoor.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:21:43,102 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:21:43,103 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:21:43,103 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:21:43,103 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:21:43,104 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/groundingdino_swinb_cogcoor.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:21:43,107 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:22:59,310 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:22:59,323 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:22:59,324 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:22:59,325 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:22:59,325 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:22:59,325 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:22:59,326 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, quiet=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:22:59,328 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:25:31,134 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:25:31,147 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:25:31,150 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:25:31,151 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:25:31,152 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:25:31,152 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:25:31,153 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:25:31,157 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:26:00,476 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:26:00,488 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:26:00,493 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:26:00,495 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:26:00,496 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:26:00,498 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:26:00,499 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=True, label_list=['pig'], val_label_list=['pig'], coco_val_path='../dataset/output_dataset/valid/annotation.json')
[0m
[36mDEBUG   [0m [36m2025-03-21 14:26:00,503 | [34mbuild model ... ...[0m
[32mINFO    [0m [32m2025-03-21 14:26:27,093 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:26:27,105 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:26:27,107 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:26:27,107 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:26:27,108 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:26:27,108 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:26:27,108 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['pig'], val_label_list=['pig'])
[0m
[36mDEBUG   [0m [36m2025-03-21 14:26:27,112 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 14:26:29,283 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-03-21 14:26:29,286 | [34mnumber of params:236717952[0m
[32mINFO    [0m [32m2025-03-21 14:26:29,291 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 6144,
  "backbone.0.patch_embed.proj.bias": 128,
  "backbone.0.patch_embed.norm.weight": 128,
  "backbone.0.patch_embed.norm.bias": 128,
  "backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "backbone.0.layers.0.downsample.reduction.weight": 131072,
  "backbone.0.layers.0.downsample.norm.weight": 512,
  "backbone.0.layers.0.downsample.norm.bias": 512,
  "backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "backbone.0.layers.1.downsample.reduction.weight": 524288,
  "backbone.0.layers.1.downsample.norm.weight": 1024,
  "backbone.0.layers.1.downsample.norm.bias": 1024,
  "backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "backbone.0.layers.2.downsample.norm.weight": 2048,
  "backbone.0.layers.2.downsample.norm.bias": 2048,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "backbone.0.norm1.weight": 256,
  "backbone.0.norm1.bias": 256,
  "backbone.0.norm2.weight": 512,
  "backbone.0.norm2.bias": 512,
  "backbone.0.norm3.weight": 1024,
  "backbone.0.norm3.bias": 1024
}[0m
[32mINFO    [0m [32m2025-03-21 14:26:29,308 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256
}[0m
[36mDEBUG   [0m [36m2025-03-21 14:26:29,314 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 14:26:30,765 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-03-21 14:26:30,766 | [34mnumber of training dataset: 1, samples: 16338[0m
[32mINFO    [0m [32m2025-03-21 14:26:31,706 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-03-21 14:26:31,948 | [34m<All keys matched successfully>[0m
[32mINFO    [0m [32m2025-03-21 14:33:24,613 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 14:33:24,626 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 14:33:24,627 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 14:33:24,628 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 14:33:24,628 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:33:24,628 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 14:33:24,628 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['pig'], val_label_list=['pig'])
[0m
[36mDEBUG   [0m [36m2025-03-21 14:33:24,636 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 14:33:26,796 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-03-21 14:33:26,800 | [34mnumber of params:236717952[0m
[32mINFO    [0m [32m2025-03-21 14:33:26,806 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 6144,
  "backbone.0.patch_embed.proj.bias": 128,
  "backbone.0.patch_embed.norm.weight": 128,
  "backbone.0.patch_embed.norm.bias": 128,
  "backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "backbone.0.layers.0.downsample.reduction.weight": 131072,
  "backbone.0.layers.0.downsample.norm.weight": 512,
  "backbone.0.layers.0.downsample.norm.bias": 512,
  "backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "backbone.0.layers.1.downsample.reduction.weight": 524288,
  "backbone.0.layers.1.downsample.norm.weight": 1024,
  "backbone.0.layers.1.downsample.norm.bias": 1024,
  "backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "backbone.0.layers.2.downsample.norm.weight": 2048,
  "backbone.0.layers.2.downsample.norm.bias": 2048,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "backbone.0.norm1.weight": 256,
  "backbone.0.norm1.bias": 256,
  "backbone.0.norm2.weight": 512,
  "backbone.0.norm2.bias": 512,
  "backbone.0.norm3.weight": 1024,
  "backbone.0.norm3.bias": 1024
}[0m
[32mINFO    [0m [32m2025-03-21 14:33:26,824 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256
}[0m
[36mDEBUG   [0m [36m2025-03-21 14:33:26,827 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 14:33:28,329 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-03-21 14:33:28,329 | [34mnumber of training dataset: 1, samples: 16338[0m
[32mINFO    [0m [32m2025-03-21 14:33:29,198 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-03-21 14:33:29,471 | [34m<All keys matched successfully>[0m
[32mINFO    [0m [32m2025-03-21 15:09:11,140 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 15:09:11,153 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 15:09:11,159 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 15:09:11,168 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 15:09:11,169 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 15:09:11,169 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 15:09:11,170 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['pig'], val_label_list=['pig'])
[0m
[36mDEBUG   [0m [36m2025-03-21 15:09:11,190 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 15:09:17,071 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-03-21 15:09:17,075 | [34mnumber of params:236717952[0m
[32mINFO    [0m [32m2025-03-21 15:09:17,079 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 6144,
  "backbone.0.patch_embed.proj.bias": 128,
  "backbone.0.patch_embed.norm.weight": 128,
  "backbone.0.patch_embed.norm.bias": 128,
  "backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "backbone.0.layers.0.downsample.reduction.weight": 131072,
  "backbone.0.layers.0.downsample.norm.weight": 512,
  "backbone.0.layers.0.downsample.norm.bias": 512,
  "backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "backbone.0.layers.1.downsample.reduction.weight": 524288,
  "backbone.0.layers.1.downsample.norm.weight": 1024,
  "backbone.0.layers.1.downsample.norm.bias": 1024,
  "backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "backbone.0.layers.2.downsample.norm.weight": 2048,
  "backbone.0.layers.2.downsample.norm.bias": 2048,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "backbone.0.norm1.weight": 256,
  "backbone.0.norm1.bias": 256,
  "backbone.0.norm2.weight": 512,
  "backbone.0.norm2.bias": 512,
  "backbone.0.norm3.weight": 1024,
  "backbone.0.norm3.bias": 1024
}[0m
[32mINFO    [0m [32m2025-03-21 15:09:17,104 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256
}[0m
[36mDEBUG   [0m [36m2025-03-21 15:09:17,107 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 15:09:18,675 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-03-21 15:09:18,676 | [34mnumber of training dataset: 1, samples: 16338[0m
[32mINFO    [0m [32m2025-03-21 15:09:19,672 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-03-21 15:09:19,979 | [34m<All keys matched successfully>[0m
[32mINFO    [0m [32m2025-03-21 15:12:07,680 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 15:12:07,681 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 15:12:07,684 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 15:12:07,685 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 15:12:07,685 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 15:12:07,685 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 15:12:07,686 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['pig'], val_label_list=['pig'])
[0m
[36mDEBUG   [0m [36m2025-03-21 15:12:07,689 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 15:12:10,305 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-03-21 15:12:10,309 | [34mnumber of params:236717952[0m
[32mINFO    [0m [32m2025-03-21 15:12:10,313 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 6144,
  "backbone.0.patch_embed.proj.bias": 128,
  "backbone.0.patch_embed.norm.weight": 128,
  "backbone.0.patch_embed.norm.bias": 128,
  "backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "backbone.0.layers.0.downsample.reduction.weight": 131072,
  "backbone.0.layers.0.downsample.norm.weight": 512,
  "backbone.0.layers.0.downsample.norm.bias": 512,
  "backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "backbone.0.layers.1.downsample.reduction.weight": 524288,
  "backbone.0.layers.1.downsample.norm.weight": 1024,
  "backbone.0.layers.1.downsample.norm.bias": 1024,
  "backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "backbone.0.layers.2.downsample.norm.weight": 2048,
  "backbone.0.layers.2.downsample.norm.bias": 2048,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "backbone.0.norm1.weight": 256,
  "backbone.0.norm1.bias": 256,
  "backbone.0.norm2.weight": 512,
  "backbone.0.norm2.bias": 512,
  "backbone.0.norm3.weight": 1024,
  "backbone.0.norm3.bias": 1024
}[0m
[32mINFO    [0m [32m2025-03-21 15:12:10,336 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256
}[0m
[36mDEBUG   [0m [36m2025-03-21 15:12:10,338 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 15:12:11,842 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-03-21 15:12:11,842 | [34mnumber of training dataset: 1, samples: 16338[0m
[32mINFO    [0m [32m2025-03-21 15:12:12,735 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-03-21 15:12:12,983 | [34m<All keys matched successfully>[0m
[32mINFO    [0m [32m2025-03-21 15:17:36,128 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 15:17:36,141 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 15:17:36,143 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 15:17:36,144 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 15:17:36,145 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 15:17:36,145 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 15:17:36,146 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['pig'], val_label_list=['pig'])
[0m
[36mDEBUG   [0m [36m2025-03-21 15:17:36,149 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 15:17:38,689 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-03-21 15:17:38,694 | [34mnumber of params:236717952[0m
[32mINFO    [0m [32m2025-03-21 15:17:38,700 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 6144,
  "backbone.0.patch_embed.proj.bias": 128,
  "backbone.0.patch_embed.norm.weight": 128,
  "backbone.0.patch_embed.norm.bias": 128,
  "backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "backbone.0.layers.0.downsample.reduction.weight": 131072,
  "backbone.0.layers.0.downsample.norm.weight": 512,
  "backbone.0.layers.0.downsample.norm.bias": 512,
  "backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "backbone.0.layers.1.downsample.reduction.weight": 524288,
  "backbone.0.layers.1.downsample.norm.weight": 1024,
  "backbone.0.layers.1.downsample.norm.bias": 1024,
  "backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "backbone.0.layers.2.downsample.norm.weight": 2048,
  "backbone.0.layers.2.downsample.norm.bias": 2048,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "backbone.0.norm1.weight": 256,
  "backbone.0.norm1.bias": 256,
  "backbone.0.norm2.weight": 512,
  "backbone.0.norm2.bias": 512,
  "backbone.0.norm3.weight": 1024,
  "backbone.0.norm3.bias": 1024
}[0m
[32mINFO    [0m [32m2025-03-21 15:17:38,722 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256
}[0m
[36mDEBUG   [0m [36m2025-03-21 15:17:38,726 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 15:17:40,241 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-03-21 15:17:40,241 | [34mnumber of training dataset: 1, samples: 16338[0m
[32mINFO    [0m [32m2025-03-21 15:17:41,237 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-03-21 15:17:41,540 | [34m<All keys matched successfully>[0m
[32mINFO    [0m [32m2025-03-21 15:47:39,534 | [34mgit:
  sha: 6c75aeb079185f5ab4a6c0fea4df24d870d0a44a, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-03-21 15:47:39,549 | [34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_odvg.py --datasets custome_data/custome_dataset.json --pretrain_model_path checkpoints/checkpoint_fsc147_best.pth --options text_encoder_type=checkpoints/bert-base-uncased[0m
[32mINFO    [0m [32m2025-03-21 15:47:39,553 | [34mFull config saved to ./gdino_train\config_args_all.json[0m
[32mINFO    [0m [32m2025-03-21 15:47:39,554 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-03-21 15:47:39,555 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-03-21 15:47:39,556 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-03-21 15:47:39,556 | [34margs: Namespace(config_file='config/cfg_fsc147_vit_b_odvg.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='custome_data/custome_dataset.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/checkpoint_fsc147_best.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=5, lr_drop=4, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['pig'], val_label_list=['pig'])
[0m
[36mDEBUG   [0m [36m2025-03-21 15:47:39,560 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 15:47:42,048 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-03-21 15:47:42,052 | [34mnumber of params:236717952[0m
[32mINFO    [0m [32m2025-03-21 15:47:42,057 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 6144,
  "backbone.0.patch_embed.proj.bias": 128,
  "backbone.0.patch_embed.norm.weight": 128,
  "backbone.0.patch_embed.norm.bias": 128,
  "backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "backbone.0.layers.0.downsample.reduction.weight": 131072,
  "backbone.0.layers.0.downsample.norm.weight": 512,
  "backbone.0.layers.0.downsample.norm.bias": 512,
  "backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "backbone.0.layers.1.downsample.reduction.weight": 524288,
  "backbone.0.layers.1.downsample.norm.weight": 1024,
  "backbone.0.layers.1.downsample.norm.bias": 1024,
  "backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "backbone.0.layers.2.downsample.norm.weight": 2048,
  "backbone.0.layers.2.downsample.norm.bias": 2048,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "backbone.0.norm1.weight": 256,
  "backbone.0.norm1.bias": 256,
  "backbone.0.norm2.weight": 512,
  "backbone.0.norm2.bias": 512,
  "backbone.0.norm3.weight": 1024,
  "backbone.0.norm3.bias": 1024
}[0m
[32mINFO    [0m [32m2025-03-21 15:47:42,072 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feature_map_proj.weight": 458752,
  "feature_map_proj.bias": 256,
  "feature_map_encoder.layers.0.norm1.weight": 256,
  "feature_map_encoder.layers.0.norm1.bias": 256,
  "feature_map_encoder.layers.0.norm2.weight": 256,
  "feature_map_encoder.layers.0.norm2.bias": 256,
  "feature_map_encoder.layers.0.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.0.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.0.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.0.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.0.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.0.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.0.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.1.norm1.weight": 256,
  "feature_map_encoder.layers.1.norm1.bias": 256,
  "feature_map_encoder.layers.1.norm2.weight": 256,
  "feature_map_encoder.layers.1.norm2.bias": 256,
  "feature_map_encoder.layers.1.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.1.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.1.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.1.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.1.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.1.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.1.mlp.linear2.bias": 256,
  "feature_map_encoder.layers.2.norm1.weight": 256,
  "feature_map_encoder.layers.2.norm1.bias": 256,
  "feature_map_encoder.layers.2.norm2.weight": 256,
  "feature_map_encoder.layers.2.norm2.bias": 256,
  "feature_map_encoder.layers.2.self_attn.in_proj_weight": 196608,
  "feature_map_encoder.layers.2.self_attn.in_proj_bias": 768,
  "feature_map_encoder.layers.2.self_attn.out_proj.weight": 65536,
  "feature_map_encoder.layers.2.self_attn.out_proj.bias": 256,
  "feature_map_encoder.layers.2.mlp.linear1.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear1.bias": 2048,
  "feature_map_encoder.layers.2.mlp.linear2.weight": 524288,
  "feature_map_encoder.layers.2.mlp.linear2.bias": 256,
  "feature_map_encoder.norm.weight": 256,
  "feature_map_encoder.norm.bias": 256,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 65536,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 131072,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 262144,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 2359296,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256
}[0m
[36mDEBUG   [0m [36m2025-03-21 15:47:42,073 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-03-21 15:47:43,532 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-03-21 15:47:43,532 | [34mnumber of training dataset: 1, samples: 16338[0m
[32mINFO    [0m [32m2025-03-21 15:47:44,428 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-03-21 15:47:44,676 | [34m<All keys matched successfully>[0m
