{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hu3PjTwht4SV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics.models.sam import SAM2VideoPredictor\n",
        "from ultralytics import SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SLHkqa_bb7A4"
      },
      "outputs": [],
      "source": [
        "def mask_to_coco_segmentation(mask_tensor, threshold=0.5):\n",
        "    # Tạo data theo coco format\n",
        "    mask_np = (mask_tensor.cpu().numpy() > threshold).astype(np.uint8) * 255\n",
        "    contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    segmentation = []\n",
        "    for cnt in contours:\n",
        "        cnt = cnt.flatten().tolist()\n",
        "        if len(cnt) >= 6:  # kiểm tra phải có ít nhất 6 points mỗi object\n",
        "            segmentation.append(cnt)\n",
        "    area = float(np.sum(mask_np > 0))\n",
        "    return segmentation, area\n",
        "\n",
        "def get_frame_at_index(video_path, frame_number):\n",
        "    # Lấy frame theo vị trí của frame number\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    if not ret or frame is None:\n",
        "        print(f\"Unable to extract frame {frame_number} from {video_path}.\")\n",
        "        return None\n",
        "    return frame\n",
        "\n",
        "def extract_boxes_from_track(video_path, track, frame_id=0):\n",
        "    # Lọc dữ liệu của frame hiện tại\n",
        "    boxes = []\n",
        "    for tracklet in track: # Duyệt qua từng tracklet\n",
        "        for data in tracklet: # Duyệt qua từng frame trong tracklet\n",
        "            if data[0] == frame_id: # Nếu frameID khớp\n",
        "                bbox = data[1:5]  # Lấy bounding box\n",
        "                boxes.append(bbox) # bbox[x, y, w, h]\n",
        "    return boxes\n",
        "\n",
        "def boxes_to_centers_nested(boxes):\n",
        "    #Lấy điểm trung tâm box\n",
        "    centers = []\n",
        "    labels = []\n",
        "    for box in boxes:\n",
        "        x, y, w, h = box\n",
        "        center_x = x + (w-x) / 2\n",
        "        center_y = y + (h-y) / 2\n",
        "        centers.append([[center_x, center_y]])\n",
        "        labels.append([1])\n",
        "    return centers, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SAM2VideoPredictor có track"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBYohoAob7A5"
      },
      "outputs": [],
      "source": [
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "video_path = r\"/content/drive/MyDrive/pig_farming/2019-11-22--11_20_15/000001/color.mp4\"\n",
        "parent_folder_name = os.path.basename(os.path.dirname(video_path))\n",
        "track = np.load(r\"/content/drive/MyDrive/pig_farming/2019-11-22--11_20_15/000001/behaviour_15.npy\", allow_pickle=True)\n",
        "\n",
        "# Lấy tọa độ box\n",
        "boxes = extract_boxes_from_track(video_path, track, frame_id=0)\n",
        "\n",
        "# Lấy điểm center\n",
        "centers_nested, labels_nested = boxes_to_centers_nested(boxes)\n",
        "\n",
        "# Model config\n",
        "# Skip 15 frames\n",
        "vid_stride=15\n",
        "overrides = dict(conf=0.25, task=\"segment\", mode=\"predict\", imgsz=1024,\n",
        "                 model=\"sam2_t.pt\", stream_buffer=False, vid_stride=vid_stride)\n",
        "predictor = SAM2VideoPredictor(overrides=overrides)\n",
        "\n",
        "# Run inference\n",
        "results = predictor(source=video_path, points=centers_nested, labels=labels_nested)\n",
        "\n",
        "# Tạo file chứa result\n",
        "base_output = \"output\"  # Main output directory\n",
        "video_output_folder = os.path.join(base_output, parent_folder_name)\n",
        "os.makedirs(video_output_folder, exist_ok=True)\n",
        "\n",
        "# Tạo subfolders cho  raw images, processed images, and annotations.\n",
        "raw_folder = os.path.join(video_output_folder, \"raw\")\n",
        "processed_folder = os.path.join(video_output_folder, \"processed\")\n",
        "annotation_folder = os.path.join(video_output_folder, \"annotations\")\n",
        "os.makedirs(raw_folder, exist_ok=True)\n",
        "os.makedirs(processed_folder, exist_ok=True)\n",
        "os.makedirs(annotation_folder, exist_ok=True)\n",
        "\n",
        "# --- Process and Save Results ---\n",
        "new_index = 0\n",
        "ann_global_id = 1\n",
        "\n",
        "# Iterate\n",
        "for result in results:\n",
        "    # \"000001_frame_0000.jpg\"\n",
        "    file_base = f\"{parent_folder_name}_frame_{new_index:04d}.jpg\"\n",
        "\n",
        "    # Save the processed image\n",
        "    processed_image_path = os.path.join(processed_folder, file_base)\n",
        "    result.save(filename=processed_image_path)\n",
        "\n",
        "    # Save the raw image.\n",
        "    # Lấy ảnh gốc từ result nếu có\n",
        "    raw_image = getattr(result, \"orig_img\", None)\n",
        "    if raw_image is None:\n",
        "        # The original frame index = new_index * vid_stride\n",
        "        raw_image = get_frame_at_index(video_path, new_index * vid_stride)\n",
        "    raw_image_path = os.path.join(raw_folder, file_base)\n",
        "    if raw_image is not None:\n",
        "        cv2.imwrite(raw_image_path, raw_image)\n",
        "    else:\n",
        "        print(f\"Failed to save raw image for frame {new_index}\")\n",
        "\n",
        "    # Build COCO-format annotations\n",
        "    annotations = []\n",
        "    if result.masks is not None:\n",
        "        mask_tensor = result.masks.data  # Tensor of shape (N, H, W)\n",
        "        if result.boxes is not None:\n",
        "            boxes = result.boxes.xyxy.cpu().numpy()  # Each box: [x1, y1, x2, y2]\n",
        "        else:\n",
        "            boxes = [None] * len(mask_tensor)\n",
        "\n",
        "        for mask, box in zip(mask_tensor, boxes):\n",
        "            segmentation, area = mask_to_coco_segmentation(mask)\n",
        "            if box is not None:\n",
        "                x1, y1, x2, y2 = box\n",
        "                bbox = [float(x1), float(y1), float(x2 - x1), float(y2 - y1)]\n",
        "            else:\n",
        "                bbox = []\n",
        "\n",
        "            annotation = {\n",
        "                \"id\": ann_global_id,\n",
        "                \"image_id\": new_index,\n",
        "                \"category_id\": 1,\n",
        "                \"segmentation\": segmentation,\n",
        "                \"area\": area,\n",
        "                \"bbox\": bbox,\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            annotations.append(annotation)\n",
        "            ann_global_id += 1\n",
        "\n",
        "    # Build COCO JSON structure\n",
        "    coco_output = {\n",
        "        \"images\": [{\"id\": new_index, \"file_name\": file_base}],\n",
        "        \"annotations\": annotations,\n",
        "        \"categories\": [{\"id\": 1, \"name\": \"pig\"}]\n",
        "    }\n",
        "\n",
        "    # Save annotation JSON in the annotation folder.\n",
        "    json_filename = f\"{parent_folder_name}_frame_{new_index:04d}.json\"\n",
        "    json_path = os.path.join(annotation_folder, json_filename)\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(coco_output, f, indent=2)\n",
        "\n",
        "    print(f\"Saved frame {new_index} of {parent_folder_name}:\")\n",
        "    print(f\"  Raw image: {raw_image_path}\")\n",
        "    print(f\"  Processed image: {processed_image_path}\")\n",
        "    print(f\"  Annotations: {json_path}\")\n",
        "\n",
        "    new_index += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Không Track dùng box sau khi lọc frame để input model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "track = np.load(r\"results_dataset/2019-11-22--11_20_15/000001/behaviour_15.npy\", allow_pickle=True)\n",
        "map_behaviour = {\n",
        "    0: \"unknown\",\n",
        "    1: \"not moving\",\n",
        "    2: \"moving\",\n",
        "    3: \"running\",\n",
        "    4: \"eating\",\n",
        "    5: \"drinking\",\n",
        "    6: \"playing\",\n",
        "    101: \"standing\",\n",
        "    102: \"lying\"\n",
        "}\n",
        "\n",
        "video_path = r\"2019-11-22--11_20_15/000001/color.mp4\"\n",
        "capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(capture.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "output_video_path = \"051119_000000.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# tạo thư mục output\n",
        "video_basename = os.path.splitext(os.path.basename(video_path))[0]\n",
        "output_dir = os.path.join(\"output\", video_basename)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load SAM model from ultralytics\n",
        "model = SAM(\"sam2.1_b.pt\")\n",
        "model.info()  \n",
        "\n",
        "ann_global_id = 1  \n",
        "\n",
        "frame_index = 0\n",
        "\n",
        "while capture.isOpened():\n",
        "    ret, frame = capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    boxes = []\n",
        "    for i in range(len(track)):  \n",
        "        for m in range(len(track[i])):  \n",
        "            if track[i][m][0] == frame_index:  \n",
        "                bbox = track[i][m][1:5]  \n",
        "                boxes.append(bbox)\n",
        "                xmin, ymin, xmax, ymax = list(map(int, bbox))\n",
        "                behavior = map_behaviour[int(track[i][m][13])]\n",
        "                label = f\"ID:{i} {behavior}\"\n",
        "                # Optionally, draw the bounding box and label on the frame\n",
        "                #cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "                #cv2.putText(frame, label, (xmin, ymin - 10),\n",
        "                #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Run SAM inference \n",
        "    results = model(source=frame, bboxes=boxes, imgsz=1024)\n",
        "    \n",
        "    # Prepare COCO-format annotations \n",
        "    annotations = []\n",
        "    for result in results:\n",
        "        # Save kết quả từ Sam\n",
        "        image_filename = os.path.join(output_dir, f\"{video_basename}_frame_{frame_index}.jpg\")\n",
        "        result.save(filename=image_filename)\n",
        "        \n",
        "        # Xây dựng COCO annotations format\n",
        "        if result.masks is not None:\n",
        "            mask_tensor = result.masks.data  # shape: (N, H, W)\n",
        "            if result.boxes is not None:  \n",
        "                boxes_from_sam = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]\n",
        "            else:\n",
        "                boxes_from_sam = [None] * len(mask_tensor)\n",
        "            \n",
        "            for mask, box in zip(mask_tensor, boxes_from_sam):\n",
        "                segmentation, area = mask_to_coco_segmentation(mask)\n",
        "                if box is not None:\n",
        "                    x1, y1, x2, y2 = box\n",
        "                    coco_bbox = [float(x1), float(y1), float(x2 - x1), float(y2 - y1)]\n",
        "                else:\n",
        "                    coco_bbox = []\n",
        "                \n",
        "                annotation = {\n",
        "                    \"id\": ann_global_id,\n",
        "                    \"image_id\": frame_index,  \n",
        "                    \"category_id\": 1,         #pig\n",
        "                    \"segmentation\": segmentation,\n",
        "                    \"area\": area,\n",
        "                    \"bbox\": coco_bbox,\n",
        "                    \"iscrowd\": 0\n",
        "                }\n",
        "                annotations.append(annotation)\n",
        "                ann_global_id += 1\n",
        "        # Tạo COCO output cho frame\n",
        "        coco_output = {\n",
        "            \"images\": [{\"id\": frame_index, \"file_name\": os.path.basename(image_filename)}],\n",
        "            \"annotations\": annotations,\n",
        "            \"categories\": [{\"id\": 1, \"name\": \"pig\"}]\n",
        "        }\n",
        "        json_filename = os.path.join(output_dir, f\"{video_basename}_frame_{frame_index}.json\")\n",
        "        with open(json_filename, \"w\") as f:\n",
        "            json.dump(coco_output, f, indent=2)\n",
        "        print(f\"Saved SAM prediction for frame {frame_index} as '{image_filename}' and annotations in '{json_filename}'.\")\n",
        "\n",
        "\n",
        "    frame_index += 1\n",
        "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "capture.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tạo video từ processed image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7CTpHxYckDN",
        "outputId": "0be0909b-c357-4974-9f14-0e3ddc0be8b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved as: 2019-11-22--11_20_15_000001.mp4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import re\n",
        "\n",
        "def compress_images_to_video(image_folder, output_video, fps=10, image_extension='.jpg'):\n",
        "\n",
        "    # Get list of image files with the given extension\n",
        "    image_files = [f for f in os.listdir(image_folder) if f.endswith(image_extension)]\n",
        "    if not image_files:\n",
        "        print(\"No images found in the folder.\")\n",
        "        return\n",
        "\n",
        "    # Define a helper function to extract the frame number from the file name.\n",
        "    def extract_frame_number(filename):\n",
        "        # The pattern looks for '_frame_' followed by one or more digits.\n",
        "        match = re.search(r'_frame_(\\d+)', filename)\n",
        "        if match:\n",
        "            return int(match.group(1))\n",
        "        else:\n",
        "            return -1  # if not found, return -1 so it sorts first\n",
        "\n",
        "    # Sort image files based on the extracted frame number.\n",
        "    image_files.sort(key=extract_frame_number)\n",
        "\n",
        "    # Read the first image to get video dimensions.\n",
        "    first_image_path = os.path.join(image_folder, image_files[0])\n",
        "    first_frame = cv2.imread(first_image_path)\n",
        "    if first_frame is None:\n",
        "        print(f\"Failed to read image: {first_image_path}\")\n",
        "        return\n",
        "    height, width, channels = first_frame.shape\n",
        "\n",
        "    # Define the video codec and create VideoWriter.\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video_writer = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
        "\n",
        "    # Write each image into the video.\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "        frame = cv2.imread(image_path)\n",
        "        if frame is None:\n",
        "            print(f\"Skipping {image_path} as it could not be read.\")\n",
        "            continue\n",
        "        video_writer.write(frame)\n",
        "\n",
        "    video_writer.release()\n",
        "    print(f\"Video saved as: {output_video}\")\n",
        "\n",
        "# Example Usage:\n",
        "image_folder = r\"/content/output/000001/processed\"  # Folder with images (e.g., 005_frame_0.jpg, 005_frame_1.jpg, ...)\n",
        "output_video = r\"2019-11-22--11_20_15_000001.mp4\"  # Desired output video file\n",
        "fps = 10  # Adjust the FPS as needed\n",
        "\n",
        "compress_images_to_video(image_folder, output_video, fps)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
